{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3253,
     "status": "ok",
     "timestamp": 1647914056394,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "Mws1_PWqdz5W",
    "outputId": "29ed4012-c4a6-430d-ef41-a9ebb98f9e41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/anaconda3/envs/tf2.6/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%cd /content/drive/My Drive/SegFormer\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from utils import clip_gradient, AvgMeter\n",
    "\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 36561,
     "status": "ok",
     "timestamp": 1647914092946,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "NFSNX-9CITYi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv.runner import init_dist\n",
    "from mmcv.utils import Config, DictAction, get_git_hash\n",
    "\n",
    "from mmseg import __version__\n",
    "from mmseg.apis import set_random_seed, train_segmentor\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.utils import collect_env, get_root_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1647914092948,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "GkBRZqjXJ82d"
   },
   "outputs": [],
   "source": [
    "from mmseg.models.segmentors import CaraSegUPer_ver2 as UNet\n",
    "from mmseg.models.segmentors import CaraSegUPer_wBiFPN as Net\n",
    "from mmseg.models.segmentors import CaraSegUPer_wBiRAFPN as Net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1647914092948,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "Q6wyzylvHpln"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, img_paths, mask_paths, aug=True, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.aug = aug\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        # image = imread(img_path)\n",
    "        # mask = imread(mask_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        # name = self.img_paths[idx].split('/')[-1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            image = cv2.resize(image, (384, 384))\n",
    "            mask = cv2.resize(mask, (384, 384)) \n",
    "        else:\n",
    "            image = cv2.resize(image, (384, 384))\n",
    "            mask = cv2.resize(mask, (384, 384)) \n",
    "\n",
    "        image = image.astype('float32') / 255\n",
    "        image = image.transpose((2, 0, 1))\n",
    "\n",
    "        mask = mask[:,:,np.newaxis]\n",
    "        mask = mask.astype('float32') / 255\n",
    "        mask = mask.transpose((2, 0, 1))\n",
    "\n",
    "        return np.asarray(image), np.asarray(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4450,
     "status": "ok",
     "timestamp": 1647914097382,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "pFfhy7JCJmJI"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "  true_positives = torch.sum(torch.round(torch.clip(y_true * y_pred, 0, 1)))\n",
    "  possible_positives = torch.sum(torch.round(torch.clip(y_true, 0, 1)))\n",
    "  recall = true_positives / (possible_positives + K.epsilon())\n",
    "  return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "  true_positives = torch.sum(torch.round(torch.clip(y_true * y_pred, 0, 1)))\n",
    "  predicted_positives = torch.sum(torch.round(torch.clip(y_pred, 0, 1)))\n",
    "  precision = true_positives / (predicted_positives + K.epsilon())\n",
    "  return precision\n",
    "\n",
    "def dice_m(y_true, y_pred):\n",
    "  precision = precision_m(y_true, y_pred)\n",
    "  recall = recall_m(y_true, y_pred)\n",
    "  return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def iou_m(y_true, y_pred):\n",
    "  precision = precision_m(y_true, y_pred)\n",
    "  recall = recall_m(y_true, y_pred)\n",
    "  return recall*precision/(recall+precision-recall*precision +K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1647914097384,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "pm_aSeXoJoC3"
   },
   "outputs": [],
   "source": [
    "class FocalLossV1(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha=0.25,\n",
    "                 gamma=2,\n",
    "                 reduction='mean',):\n",
    "        super(FocalLossV1, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.crit = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, label):\n",
    "        # compute loss\n",
    "        logits = logits.float() # use fp32 if logits is fp16\n",
    "        with torch.no_grad():\n",
    "            alpha = torch.empty_like(logits).fill_(1 - self.alpha)\n",
    "            alpha[label == 1] = self.alpha\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(label == 1, probs, 1 - probs)\n",
    "        ce_loss = self.crit(logits, label.float())\n",
    "        loss = (alpha * torch.pow(1 - pt, self.gamma) * ce_loss)\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        if self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, eps=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        \"\"\"\n",
    "        Forward function\n",
    "        :param pred: Prediction tensor containing raw network outputs (no logit) (B x C x H x W)\n",
    "        :param label: Label mask tensor (B x C x H x W)\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(pred)\n",
    "        true_pos = torch.sum(probs * label, dim=[0, 2, 3])\n",
    "        false_neg = torch.sum(label * (1 - probs), dim=[0, 2, 3])\n",
    "        false_pos = torch.sum(probs * (1 - label), dim=[0, 2, 3])\n",
    "        return 1 - torch.mean(\n",
    "            (true_pos + self.eps)\n",
    "            / (\n",
    "                true_pos\n",
    "                + self.alpha * false_neg\n",
    "                + (1 - self.alpha) * false_pos\n",
    "                + self.eps\n",
    "            )\n",
    "        )\n",
    "\n",
    "class FocalTverskyLoss(TverskyLoss):\n",
    "    def __init__(self, gamma=4 / 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        probs = torch.sigmoid(pred)\n",
    "        true_pos = torch.sum(probs * label, dim=[0, 2, 3])\n",
    "        false_neg = torch.sum(label * (1 - probs), dim=[0, 2, 3])\n",
    "        false_pos = torch.sum(probs * (1 - label), dim=[0, 2, 3])\n",
    "\n",
    "        t = (true_pos + self.eps) / (\n",
    "            true_pos + self.alpha * false_neg + (1 - self.alpha) * false_pos + self.eps\n",
    "        )\n",
    "\n",
    "        x = torch.pow(1 - t, 1 / self.gamma)\n",
    "\n",
    "        return x #torch.sum(x)\n",
    "def structure_loss_v2(pred, mask):\n",
    "    weit = 1 + 5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n",
    "    wfocal = FocalLossV1()(pred, mask)\n",
    "    wfocal = (wfocal*weit).sum(dim=(2,3)) / weit.sum(dim=(2, 3))\n",
    "\n",
    "    \n",
    "    wiou = FocalTverskyLoss()(pred,mask)\n",
    "    return (wfocal + wiou).mean()\n",
    "def structure_loss(pred, mask):\n",
    "    weit = 1 + 5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n",
    "    wfocal = FocalLossV1()(pred, mask)\n",
    "    wfocal = (wfocal*weit).sum(dim=(2,3)) / weit.sum(dim=(2, 3))\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    inter = ((pred * mask)*weit).sum(dim=(2, 3))\n",
    "    union = ((pred + mask)*weit).sum(dim=(2, 3))\n",
    "    wiou = 1 - (inter + 1)/(union - inter+1)\n",
    "    return (wfocal + wiou).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647914097384,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "z8M-oyZNJqUL"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch, lr_scheduler, deep=False):\n",
    "    model.train()\n",
    "    # ---- multi-scale training ----\n",
    "    size_rates = [256/384, 1, 512/384]\n",
    "    loss_record = AvgMeter()\n",
    "    dice, iou = AvgMeter(), AvgMeter()\n",
    "    for i, pack in enumerate(train_loader, start=1):\n",
    "        if epoch <= 1:\n",
    "                optimizer.param_groups[0][\"lr\"] = (epoch * i) / (1.0 * total_step) * init_lr\n",
    "        else:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        for rate in size_rates: \n",
    "            optimizer.zero_grad()\n",
    "            # ---- data prepare ----\n",
    "            images, gts = pack\n",
    "            images = Variable(images).cuda()\n",
    "            gts = Variable(gts).cuda()\n",
    "            # ---- rescale ----\n",
    "            trainsize = int(round(trainsize_init*rate/32)*32)\n",
    "            images = F.upsample(images, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            gts = F.upsample(gts, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            # ---- forward ----\n",
    "            map4, map3, map2, map1 = model(images)\n",
    "           # print(map4.shape, map3.shape, map2.shape, map1.shape)\n",
    "            map1 = F.upsample(map1, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            map2 = F.upsample(map2, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            map3 = F.upsample(map3, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            map4 = F.upsample(map4, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "            loss = structure_loss(map1, gts) + structure_loss(map2, gts) + structure_loss(map3, gts) + structure_loss(map4, gts)\n",
    "            # ---- metrics ----\n",
    "            dice_score = dice_m(map2, gts)\n",
    "            iou_score = iou_m(map2, gts)\n",
    "            # ---- backward ----\n",
    "            loss.backward()\n",
    "            clip_gradient(optimizer, clip)\n",
    "            optimizer.step()\n",
    "            # ---- recording loss ----\n",
    "            if rate == 1:\n",
    "                loss_record.update(loss.data, batchsize)\n",
    "                dice.update(dice_score.data, batchsize)\n",
    "                iou.update(iou_score.data, batchsize)\n",
    "\n",
    "        # ---- train visualization ----\n",
    "        if i == total_step:\n",
    "            print('{} Training Epoch [{:03d}/{:03d}], '\n",
    "                  '[loss: {:0.4f}, dice: {:0.4f}, iou: {:0.4f}]'.\n",
    "                  format(datetime.now(), epoch, num_epochs,\\\n",
    "                         loss_record.show(), dice.show(), iou.show()))\n",
    "\n",
    "    ckpt_path = save_path + 'last.pth'\n",
    "    print('[Saving Checkpoint:]', ckpt_path)\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': lr_scheduler.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, ckpt_path)\n",
    "\n",
    "    log = OrderedDict([\n",
    "        ('loss', loss_record.show()), ('dice', dice.show()), ('iou', iou.show()),\n",
    "    ])\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647914097385,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "AFOm9drLJslH"
   },
   "outputs": [],
   "source": [
    "def recall_np(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_np(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def dice_np(y_true, y_pred):\n",
    "    precision = precision_np(y_true, y_pred)\n",
    "    recall = recall_np(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def iou_np(y_true, y_pred):\n",
    "    intersection = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    union = np.sum(y_true)+np.sum(y_pred)-intersection\n",
    "    return intersection/(union+K.epsilon())\n",
    "\n",
    "def acc_np(y_true, y_pred):\n",
    "    acc = np.sum(y_true==y_pred)\n",
    "    h,w = y_true.shape\n",
    "    return acc/(h*w+K.epsilon())\n",
    "\n",
    "def get_scores(gts, prs):\n",
    "    mean_precision = 0\n",
    "    mean_recall = 0\n",
    "    mean_iou = 0\n",
    "    mean_dice = 0\n",
    "    mean_acc = 0\n",
    "    for gt, pr in zip(gts, prs):\n",
    "        mean_precision += precision_np(gt, pr)\n",
    "        mean_recall += recall_np(gt, pr)\n",
    "        mean_iou += iou_np(gt, pr)\n",
    "        mean_dice += dice_np(gt, pr)\n",
    "        mean_acc += acc_np(gt, pr)\n",
    "\n",
    "    mean_precision /= len(gts)\n",
    "    mean_recall /= len(gts)\n",
    "    mean_iou /= len(gts)\n",
    "    mean_dice /= len(gts)        \n",
    "    mean_acc /= len(gts) \n",
    "    print(f\"scores: dice={mean_dice}, miou={mean_iou}, precision={mean_precision}, recall={mean_recall}, accuracy ={mean_acc}\")\n",
    "\n",
    "    return (mean_iou, mean_dice, mean_precision, mean_recall)\n",
    "\n",
    "\n",
    "\n",
    "def inference(model,writer=None,epoch=None):\n",
    "    print(\"#\"*20)\n",
    "    model.eval()\n",
    "    dataset_names = ['ISIC']\n",
    "    for dataset_name in dataset_names:\n",
    "        data_path = f'../dataset/ISIC/384/testdataset/'\n",
    "        print(data_path)\n",
    "        X_test = glob('{}/images/*'.format(data_path))\n",
    "        X_test.sort()\n",
    "        y_test = glob('{}/masks/*'.format(data_path))\n",
    "        y_test.sort()\n",
    "\n",
    "        test_dataset = Dataset(X_test, y_test)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False)\n",
    "\n",
    "        print('Dataset_name:', dataset_name)\n",
    "        tp_all = 0\n",
    "        fp_all = 0\n",
    "        fn_all = 0\n",
    "        mean_iou = 0\n",
    "        gts = []\n",
    "        prs = []\n",
    "        losses = []\n",
    "        for i, pack in enumerate(test_loader, start=1):\n",
    "            image, gt_ = pack\n",
    "            # name = name[0]\n",
    "            gt = gt_[0][0]\n",
    "            gt = np.asarray(gt, np.float32)\n",
    "            image = image.cuda()\n",
    "\n",
    "            res, res2, res3, res4 = model(image)\n",
    "            res = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
    "            loss = structure_loss_v2(res.cpu(), gt_)\n",
    "            losses.append(loss.cpu().detach().numpy().squeeze())\n",
    "            res = res.sigmoid().data.cpu().numpy().squeeze()\n",
    "            res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "            pr = res.round()\n",
    "            # cv2.imwrite(os.path.join(save_path, dataset_name, name), res)\n",
    "            gts.append(gt)\n",
    "            prs.append(pr)\n",
    "        mean_iou, mean_dice, mean_precision, mean_recall = get_scores(gts, prs)\n",
    "#         writer.add_scalar(dataset_name + ' val loss',\n",
    "#                             np.mean(losses),\n",
    "#                             epoch )\n",
    "#         writer.add_scalar(dataset_name + ' val dice',\n",
    "#                             mean_dice,\n",
    "#                             epoch )\n",
    "#         writer.add_scalar(dataset_name + ' val iou',\n",
    "#                             mean_iou,\n",
    "#                             epoch )\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.transforms.functional import *\n",
    "#import torchvision.transforms as transforms\n",
    "from albumentations.augmentations.geometric import  resize,rotate\n",
    "import albumentations.augmentations.crops.transforms as crop\n",
    "import albumentations.augmentations.transforms as transforms\n",
    "train_transform = Compose([\n",
    "            rotate.RandomRotate90(),\n",
    "            transforms.Flip(),\n",
    "            transforms.HueSaturationValue(),\n",
    "            transforms.RandomBrightnessContrast(),\n",
    "            transforms.GaussianBlur(),\n",
    "            transforms.Transpose(),\n",
    "            \n",
    "#             resize.Resize(384, 384),\n",
    "#     OneOf([\n",
    "#                 crop.RandomCrop(224, 224, p=1),\n",
    "#                 crop.CenterCrop(224, 224, p=1)\n",
    "#             ], p=0.2),\n",
    "    resize.Resize(384, 384),\n",
    "        ], p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11328686,
     "status": "ok",
     "timestamp": 1647925426060,
     "user": {
      "displayName": "Đức Nguyễn Thanh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17339142369468246592"
     },
     "user_tz": -420
    },
    "id": "Sq_wUsi6t3eo",
    "outputId": "fe0ea9b1-a3f5-4c02-d6c9-b7d55238560f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path existed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 20:55:30,682 - mmseg - INFO - Use load_from_local loader\n",
      "2022-07-09 20:55:30,767 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.weight, head.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "../dataset/ISIC/384/testdataset/\n",
      "Dataset_name: ISIC\n",
      "scores: dice=0.9039473368139728, miou=0.8397185246272749, precision=0.9195016311808233, recall=0.9145201417698453, accuracy =0.9633764674514371\n",
      "####################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# ---- flops and params ----\\nparams = model.parameters()\\noptimizer = torch.optim.Adam(params, init_lr)\\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \\n                                    T_max=len(train_loader)*num_epochs,\\n                                    eta_min=init_lr/1000)\\n\\n\\n\\nstart_epoch = 1\\n\\nckpt_path = \\'\\'\\nif ckpt_path != \\'\\':\\n    log = pd.read_csv(ckpt_path.replace(\\'last.pth\\', \\'log.csv\\'))\\n    checkpoint = torch.load(ckpt_path)\\n    start_epoch = checkpoint[\\'epoch\\']\\n    model.load_state_dict(checkpoint[\\'state_dict\\'])\\n    lr_scheduler.load_state_dict(checkpoint[\\'scheduler\\'])\\n    optimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\n\\nprint(\"#\"*20, f\"Start Training\", \"#\"*20)\\nfor epoch in range(start_epoch, num_epochs+1):\\n    #inference(model,writer,epoch)\\n    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\\n\\n    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \\n            train_log[\\'loss\\'].item(), train_log[\\'dice\\'].item(), train_log[\\'iou\\'].item(),  \\n    ], index=[\\'epoch\\', \\'lr\\', \\'loss\\', \\'dice\\', \\'iou\\'])\\n    log = log.append(log_tmp, ignore_index=True)\\n    log.to_csv(f\\'./snapshots/{train_save}/log.csv\\', index=False)\\n    writer.add_scalar(\\'training loss\\',\\n                            train_log[\\'loss\\'].item(),\\n                            epoch )\\n    writer.add_scalar(\\'training dice\\',\\n                            train_log[\\'dice\\'].item(),\\n                            epoch )\\n    writer.add_scalar(\\'training iou\\',\\n                            train_log[\\'iou\\'].item(),\\n                            epoch )\\n    \\n    if epoch >= num_epochs-20:\\n        inference(model,writer,epoch)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('logsISIC_RA/lan2')\n",
    "\n",
    "init_lr = 1e-4\n",
    "batchsize = 8\n",
    "trainsize_init = 384\n",
    "clip = 0.5\n",
    "num_epochs= 50\n",
    "train_save = 'BiRAFPN_ISIC_2'\n",
    "\n",
    "save_path = './snapshots/{}/'.format(train_save)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "else:\n",
    "    print(\"Save path existed\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "log = pd.DataFrame(index=[], columns=[\n",
    "    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n",
    "])\n",
    "train_img_paths = []\n",
    "train_mask_paths = []\n",
    "train_img_paths = glob('../dataset/ISIC/384/traindataset/images/*')#+glob('../dataset/ISIC/384/valdataset/images/*')\n",
    "train_mask_paths = glob('../dataset/ISIC/384/traindataset/masks/*')#+glob('../dataset/ISIC/384/valdataset/masks/*')\n",
    "train_img_paths.sort()\n",
    "train_mask_paths.sort()\n",
    "\n",
    "train_dataset = Dataset(train_img_paths, train_mask_paths,transform =train_transform)#train_transform\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                   compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth').cuda()\n",
    "model.load_state_dict(torch.load(save_path+\"last.pth\")['state_dict'])\n",
    "inference(model,None,None)\n",
    "\"\"\"\n",
    "# ---- flops and params ----\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, init_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                    T_max=len(train_loader)*num_epochs,\n",
    "                                    eta_min=init_lr/1000)\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "ckpt_path = ''\n",
    "if ckpt_path != '':\n",
    "    log = pd.read_csv(ckpt_path.replace('last.pth', 'log.csv'))\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print(\"#\"*20, f\"Start Training\", \"#\"*20)\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    #inference(model,writer,epoch)\n",
    "    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n",
    "\n",
    "    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \n",
    "            train_log['loss'].item(), train_log['dice'].item(), train_log['iou'].item(),  \n",
    "    ], index=['epoch', 'lr', 'loss', 'dice', 'iou'])\n",
    "    log = log.append(log_tmp, ignore_index=True)\n",
    "    log.to_csv(f'./snapshots/{train_save}/log.csv', index=False)\n",
    "    writer.add_scalar('training loss',\n",
    "                            train_log['loss'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training dice',\n",
    "                            train_log['dice'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training iou',\n",
    "                            train_log['iou'].item(),\n",
    "                            epoch )\n",
    "    \n",
    "    if epoch >= num_epochs-20:\n",
    "        inference(model,writer,epoch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('logsRA_new_bottleneck_v2/lan2')\n",
    "\n",
    "init_lr = 1e-4\n",
    "batchsize = 8\n",
    "trainsize_init = 384\n",
    "clip = 0.5\n",
    "num_epochs= 30\n",
    "train_save = 'BiRAFPN_2_new_bottleneck_v2'\n",
    "\n",
    "save_path = './snapshots/{}/'.format(train_save)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "else:\n",
    "    print(\"Save path existed\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "log = pd.DataFrame(index=[], columns=[\n",
    "    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n",
    "])\n",
    "train_img_paths = []\n",
    "train_mask_paths = []\n",
    "train_img_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/image/*')\n",
    "train_mask_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/mask/*')\n",
    "train_img_paths.sort()\n",
    "train_mask_paths.sort()\n",
    "\n",
    "train_dataset = Dataset(train_img_paths, train_mask_paths,transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                  compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth').cuda()\n",
    "\n",
    "# ---- flops and params ----\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, init_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                    T_max=len(train_loader)*num_epochs,\n",
    "                                    eta_min=init_lr/1000)\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "ckpt_path = ''\n",
    "if ckpt_path != '':\n",
    "    log = pd.read_csv(ckpt_path.replace('last.pth', 'log.csv'))\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print(\"#\"*20, f\"Start Training\", \"#\"*20)\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n",
    "\n",
    "    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \n",
    "            train_log['loss'].item(), train_log['dice'].item(), train_log['iou'].item(),  \n",
    "    ], index=['epoch', 'lr', 'loss', 'dice', 'iou'])\n",
    "    log = log.append(log_tmp, ignore_index=True)\n",
    "    log.to_csv(f'./snapshots/{train_save}/log.csv', index=False)\n",
    "    writer.add_scalar('training loss',\n",
    "                            train_log['loss'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training dice',\n",
    "                            train_log['dice'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training iou',\n",
    "                            train_log['iou'].item(),\n",
    "                            epoch )\n",
    "    \n",
    "    if epoch >= num_epochs-20:\n",
    "        inference(model,writer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('logsRA_new_bottleneck_v2/lan6')\n",
    "\n",
    "init_lr = 1e-4\n",
    "batchsize = 8\n",
    "trainsize_init = 384\n",
    "clip = 0.5\n",
    "num_epochs= 30\n",
    "train_save = 'BiRAFPN_3_new_bottleneck_v2'\n",
    "\n",
    "save_path = './snapshots/{}/'.format(train_save)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "else:\n",
    "    print(\"Save path existed\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "log = pd.DataFrame(index=[], columns=[\n",
    "    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n",
    "])\n",
    "train_img_paths = []\n",
    "train_mask_paths = []\n",
    "train_img_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/image/*')\n",
    "train_mask_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/mask/*')\n",
    "train_img_paths.sort()\n",
    "train_mask_paths.sort()\n",
    "\n",
    "train_dataset = Dataset(train_img_paths, train_mask_paths,transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                  compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth').cuda()\n",
    "\n",
    "# ---- flops and params ----\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, init_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                    T_max=len(train_loader)*num_epochs,\n",
    "                                    eta_min=init_lr/1000)\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "ckpt_path = ''\n",
    "if ckpt_path != '':\n",
    "    log = pd.read_csv(ckpt_path.replace('last.pth', 'log.csv'))\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print(\"#\"*20, f\"Start Training\", \"#\"*20)\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n",
    "\n",
    "    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \n",
    "            train_log['loss'].item(), train_log['dice'].item(), train_log['iou'].item(),  \n",
    "    ], index=['epoch', 'lr', 'loss', 'dice', 'iou'])\n",
    "    log = log.append(log_tmp, ignore_index=True)\n",
    "    log.to_csv(f'./snapshots/{train_save}/log.csv', index=False)\n",
    "    writer.add_scalar('training loss',\n",
    "                            train_log['loss'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training dice',\n",
    "                            train_log['dice'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training iou',\n",
    "                            train_log['iou'].item(),\n",
    "                            epoch )\n",
    "    \n",
    "    if epoch >= num_epochs-20:\n",
    "        inference(model,writer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 07:08:32,382 - mmseg - INFO - Use load_from_local loader\n",
      "2022-06-03 07:08:32,453 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.weight, head.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Start Training ####################\n",
      "2022-06-03 07:11:56.016364 Training Epoch [001/030], [loss: 2.5475, dice: 0.7424, iou: 0.5989]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:15:20.478696 Training Epoch [002/030], [loss: 1.7704, dice: 0.8021, iou: 0.6816]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:18:44.814011 Training Epoch [003/030], [loss: 1.4272, dice: 0.8472, iou: 0.7412]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:22:09.572724 Training Epoch [004/030], [loss: 1.2520, dice: 0.8630, iou: 0.7705]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:25:34.102038 Training Epoch [005/030], [loss: 0.9965, dice: 0.8994, iou: 0.8213]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:28:58.845722 Training Epoch [006/030], [loss: 1.0928, dice: 0.8947, iou: 0.8161]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:32:23.552478 Training Epoch [007/030], [loss: 1.1034, dice: 0.8815, iou: 0.7969]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:35:48.111099 Training Epoch [008/030], [loss: 0.9987, dice: 0.9047, iou: 0.8301]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:39:12.768153 Training Epoch [009/030], [loss: 1.0923, dice: 0.8719, iou: 0.7835]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "2022-06-03 07:42:37.317666 Training Epoch [010/030], [loss: 0.8711, dice: 0.9207, iou: 0.8561]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.8453897630955457, miou=0.7865349191359929, precision=0.931969482645656, recall=0.8252373676353149\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9083794028413812, miou=0.8515653668732511, precision=0.9080268842744362, recall=0.9370724275014194\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7429484809083925, miou=0.669890826236646, precision=0.7655169027132114, recall=0.7829788368216124\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8723896948886385, miou=0.8004243266520485, precision=0.8218105142848365, recall=0.9699086245715934\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8000719966032618, miou=0.7203488624686276, precision=0.7540355192207121, recall=0.8998306769446663\n",
      "####################\n",
      "2022-06-03 07:47:06.048003 Training Epoch [011/030], [loss: 0.9170, dice: 0.9173, iou: 0.8513]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9084770056288966, miou=0.8499991970531479, precision=0.935542943743343, recall=0.9045552447893702\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.8855402086131802, miou=0.832133277620939, precision=0.8801045093915311, recall=0.9336257874428182\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7823909604752777, miou=0.7041567338528159, precision=0.7824870396338859, recall=0.8558121645120267\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8450862331231899, miou=0.7771219280205955, precision=0.797239474932237, recall=0.9712216995382262\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7827142051522761, miou=0.7079499033427501, precision=0.7288242160208449, recall=0.912970370140841\n",
      "####################\n",
      "2022-06-03 07:51:34.572430 Training Epoch [012/030], [loss: 0.8199, dice: 0.9340, iou: 0.8778]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.8996057262669062, miou=0.8395761324477824, precision=0.9552618550487207, recall=0.8762897211393834\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9159351597081479, miou=0.8598788374134939, precision=0.9297405048678312, recall=0.9232058159220861\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7778223836791187, miou=0.69507690378084, precision=0.815301771982204, recall=0.7929224279422327\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8696687377842457, miou=0.8041797260088992, precision=0.8317509100422195, recall=0.920785861482541\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7976884611439687, miou=0.7218911281885524, precision=0.7607854072199378, recall=0.8689432188406098\n",
      "####################\n",
      "2022-06-03 07:56:03.323032 Training Epoch [013/030], [loss: 0.8299, dice: 0.9226, iou: 0.8605]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9044835196483209, miou=0.8501941956895886, precision=0.9482815974919806, recall=0.8876512842273045\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9056156511479796, miou=0.8539688694258323, precision=0.9219287129968474, recall=0.9253429100791297\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7968645526991911, miou=0.7174502447080234, precision=0.8205095740391352, recall=0.8305910158397\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9030093893602814, miou=0.8326410227065849, precision=0.869023076663294, recall=0.9543031100252712\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7900142935568979, miou=0.7136627485624322, precision=0.7456480417252611, recall=0.9051764281199532\n",
      "####################\n",
      "2022-06-03 08:00:31.899346 Training Epoch [014/030], [loss: 0.8957, dice: 0.9147, iou: 0.8490]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9164881176570282, miou=0.8637052455014985, precision=0.9467763851437168, recall=0.9089583939457709\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9199340601991595, miou=0.8710658560685205, precision=0.913690897382829, recall=0.9515338085099833\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8033646947537908, miou=0.7237242645021321, precision=0.8120175432338688, recall=0.8466828921211413\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8861023874378771, miou=0.8177585927912968, precision=0.8437841362421322, recall=0.9653117003876908\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8035511996526754, miou=0.7260104210356051, precision=0.7751453913000548, recall=0.8971355941815432\n",
      "####################\n",
      "2022-06-03 08:05:00.850343 Training Epoch [015/030], [loss: 0.7516, dice: 0.9338, iou: 0.8781]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9143792222773414, miou=0.8607671036889522, precision=0.948676939891405, recall=0.9060563121305795\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9096178191524389, miou=0.8604959147155334, precision=0.9147914681701543, recall=0.939869693505879\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.8036502064272391, miou=0.7253331694231795, precision=0.8152958649825075, recall=0.8476096854194509\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8928240770457551, miou=0.8245918090382103, precision=0.8535267393915068, recall=0.9614237497729725\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7628954278364037, miou=0.6854382734345537, precision=0.7143036219521227, recall=0.895849203716639\n",
      "####################\n",
      "2022-06-03 08:09:29.657805 Training Epoch [016/030], [loss: 0.7240, dice: 0.9467, iou: 0.9004]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.917116598630243, miou=0.8643711960060009, precision=0.952044249622673, recall=0.9037668664532167\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.906985609584836, miou=0.8588171199320452, precision=0.9136969195044377, recall=0.9383937809015576\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8200243537527192, miou=0.7393084294516287, precision=0.8278438655782249, recall=0.8610050029532258\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.89281609363913, miou=0.8261467826291994, precision=0.8597339790389177, recall=0.956959011314449\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7760238331153007, miou=0.6937335402581066, precision=0.7378149686009208, recall=0.9008996675224671\n",
      "####################\n",
      "2022-06-03 08:13:58.461565 Training Epoch [017/030], [loss: 0.8065, dice: 0.9253, iou: 0.8698]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9243678555015525, miou=0.8771833709854076, precision=0.9466626182934113, recall=0.9206120284119139\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9138763669872412, miou=0.8646118443614996, precision=0.9183938943558221, recall=0.9402541337463647\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8290768374329343, miou=0.7514313551110224, precision=0.8260426963560109, recall=0.8878287152457689\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9018911801667525, miou=0.8367405579599752, precision=0.8687361440015041, recall=0.958890174590195\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7980752640693255, miou=0.7202762947930584, precision=0.7504015005964054, recall=0.9273908021888864\n",
      "####################\n",
      "2022-06-03 08:18:27.331726 Training Epoch [018/030], [loss: 0.6955, dice: 0.9304, iou: 0.8796]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9078691993306138, miou=0.8560966364348067, precision=0.9383242064620585, recall=0.8980865353505351\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.912738051949467, miou=0.8634821842134655, precision=0.922190002665375, recall=0.9350954384943058\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8073508331446183, miou=0.7275503575326703, precision=0.8218736484566883, recall=0.8575074816337067\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8944676556821195, miou=0.8305986687497615, precision=0.8673804203561565, recall=0.9542838145089011\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8029980726066023, miou=0.7273688557116865, precision=0.7642838447887272, recall=0.9214325872399924\n",
      "####################\n",
      "2022-06-03 08:22:56.363113 Training Epoch [019/030], [loss: 0.7391, dice: 0.9392, iou: 0.8910]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9136389489623467, miou=0.8608565745461604, precision=0.9319055571086688, recall=0.914559481036592\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9127590241409552, miou=0.8651309762582473, precision=0.9162109279080539, recall=0.9434634257419717\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8207169473062823, miou=0.7376446144093225, precision=0.8292858875734399, recall=0.8611088924240372\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8783683820735856, miou=0.8044088375346143, precision=0.8289975644847761, recall=0.9644384676979283\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8141672444678529, miou=0.7307082396088319, precision=0.7640370195147236, recall=0.9283907491849216\n",
      "####################\n",
      "2022-06-03 08:27:24.792881 Training Epoch [020/030], [loss: 0.7745, dice: 0.9385, iou: 0.8885]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9098490381389428, miou=0.8623287578277143, precision=0.9474202623850562, recall=0.8969550150060772\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9227716146172436, miou=0.871369586193194, precision=0.9286547753617047, recall=0.9367164481295733\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8260001305209851, miou=0.7474223824128486, precision=0.8395261378512047, recall=0.863994046794449\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9054904474297776, miou=0.8421784439637369, precision=0.8783823530988286, recall=0.9548006830416867\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8103856195275769, miou=0.7300272002365105, precision=0.7658257681190686, recall=0.9148118718873525\n",
      "####################\n",
      "2022-06-03 08:31:53.742319 Training Epoch [021/030], [loss: 0.6550, dice: 0.9408, iou: 0.8960]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9180118620796704, miou=0.867888253315323, precision=0.9387486279267907, recall=0.9192148695687837\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.909086894109527, miou=0.8623523300086727, precision=0.9214616866315195, recall=0.9349608902415611\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.820822187687896, miou=0.7423741684784746, precision=0.8304075636653483, recall=0.8673045975889481\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9036501988511235, miou=0.8394014327572952, precision=0.8715481837752296, recall=0.9590132838396689\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7995311464167421, miou=0.7205925176235018, precision=0.7518903316519813, recall=0.930592988620033\n",
      "####################\n",
      "2022-06-03 08:36:22.364621 Training Epoch [022/030], [loss: 0.6208, dice: 0.9544, iou: 0.9144]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9215923687382614, miou=0.871498851471667, precision=0.9497269666573837, recall=0.912559626044736\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.9203907601264278, miou=0.8730226124994638, precision=0.9167185710855976, recall=0.9497457818820947\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.827606348510351, miou=0.7503771734044061, precision=0.8373141474475685, recall=0.8720441017585846\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.897959322151738, miou=0.8345714773272178, precision=0.8660579451615023, recall=0.9595578085487164\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8082520277791204, miou=0.7282000852942342, precision=0.7647837828967856, recall=0.9254287177591733\n",
      "####################\n",
      "2022-06-03 08:40:51.454160 Training Epoch [023/030], [loss: 0.6587, dice: 0.9426, iou: 0.8956]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9214810911825271, miou=0.871258594169508, precision=0.9375505059043244, recall=0.9211274061568279\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9165872448472245, miou=0.8668858909170992, precision=0.9195680652898305, recall=0.9407425417887111\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8107746356152126, miou=0.7365240916673352, precision=0.8146669998034026, recall=0.8756431704959353\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8980698303498295, miou=0.8341979384332817, precision=0.8700473801815878, recall=0.9549182849946846\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8036188046180058, miou=0.7288922769507324, precision=0.7723978128512893, recall=0.9029652928996662\n",
      "####################\n",
      "2022-06-03 08:45:20.385232 Training Epoch [024/030], [loss: 0.6472, dice: 0.9378, iou: 0.8902]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9144086384750001, miou=0.8647706972500171, precision=0.9479131748668179, recall=0.901402463165191\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.923887434333569, miou=0.8763248237699239, precision=0.9377004438112926, recall=0.9326439133904358\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8200325476279795, miou=0.740833379311895, precision=0.8406217591671844, recall=0.8544015291446854\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.897181371434785, miou=0.8293352154456624, precision=0.8597871661675984, recall=0.9602487461757604\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8288902869499167, miou=0.7545487758194698, precision=0.8032124418737542, recall=0.9024042678490884\n",
      "####################\n",
      "2022-06-03 08:49:48.945272 Training Epoch [025/030], [loss: 0.6274, dice: 0.9534, iou: 0.9123]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9155935840479144, miou=0.8677225207530722, precision=0.9472215866883376, recall=0.9047469828925461\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9144547500304462, miou=0.8657342479646223, precision=0.9235726077060752, recall=0.9353615598009776\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.825074037737444, miou=0.7472417667763116, precision=0.8396702472868021, recall=0.8626369434258385\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9050843990577504, miou=0.8403972397019388, precision=0.8714030011564294, recall=0.9606012741746696\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8190974213386497, miou=0.741778700693432, precision=0.7822252228616231, recall=0.9080982124797511\n",
      "####################\n",
      "2022-06-03 08:54:17.374928 Training Epoch [026/030], [loss: 0.6302, dice: 0.9484, iou: 0.9081]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9191038438473469, miou=0.8704697703619027, precision=0.9421256018768521, recall=0.9119539935297272\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.909269449268636, miou=0.8616505437912875, precision=0.9186532040211656, recall=0.9362707485930751\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8264096915259252, miou=0.7485638463223749, precision=0.8340223110796644, recall=0.873017356706212\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8967587398675894, miou=0.8294558925109531, precision=0.8585143848927419, recall=0.9621815410577006\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8088413396067414, miou=0.7317727040947389, precision=0.7698882410437933, recall=0.9183093325422048\n",
      "####################\n",
      "2022-06-03 08:58:46.545065 Training Epoch [027/030], [loss: 0.6028, dice: 0.9624, iou: 0.9282]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9200028028091256, miou=0.8723704142427715, precision=0.9431295355260313, recall=0.9131747601952585\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9117086319421774, miou=0.8635315524983315, precision=0.9164603758708975, recall=0.9407366234394149\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8244358089971338, miou=0.7466721600908646, precision=0.8308993756729565, recall=0.8754309153013952\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8991812721649555, miou=0.8333230827707061, precision=0.8605329813047291, recall=0.9647852904759213\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8122370591825343, miou=0.7340956562989316, precision=0.7700946875151943, recall=0.916377894159909\n",
      "####################\n",
      "2022-06-03 09:03:15.102674 Training Epoch [028/030], [loss: 0.6602, dice: 0.9548, iou: 0.9148]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9160680536841356, miou=0.868420528771359, precision=0.9473988633422468, recall=0.9050851462969648\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9103589303037193, miou=0.8628415747953777, precision=0.9210104924199625, recall=0.9352207998891529\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8241382683316899, miou=0.7462639260858379, precision=0.8377658580317078, recall=0.8665407877769901\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9041385309717832, miou=0.8410313270028185, precision=0.8704932389598774, recall=0.9624007309982991\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8238357927496527, miou=0.747363992964489, precision=0.7901001911262219, recall=0.9112865570638551\n",
      "####################\n",
      "2022-06-03 09:07:44.089360 Training Epoch [029/030], [loss: 0.6139, dice: 0.9563, iou: 0.9175]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.9182949429252409, miou=0.8705647395269536, precision=0.946392649715706, recall=0.9080438511769193\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9133509717910766, miou=0.8649976598205372, precision=0.9201237687507609, recall=0.9380909171598989\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8246072223978883, miou=0.7463866415372749, precision=0.8354310798465183, recall=0.8692354219562276\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9017226734952198, miou=0.8372673010654691, precision=0.8667472987918985, recall=0.9622051669594359\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8244437994615557, miou=0.7485184735637523, precision=0.7893035515227121, recall=0.9108706550136385\n",
      "####################\n",
      "2022-06-03 09:12:12.862441 Training Epoch [030/030], [loss: 0.5718, dice: 0.9625, iou: 0.9282]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_4_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9198297162430407, miou=0.872243111286156, precision=0.9442654599069285, recall=0.9113251425273419\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9198779235369814, miou=0.8719127659345884, precision=0.9193892769309134, recall=0.9459350290743841\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8246755184515572, miou=0.7467886244739181, precision=0.8330779325148581, recall=0.8723106780965452\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8999209619278473, miou=0.8347814228363255, precision=0.8639654150414854, recall=0.9623036404853613\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8199200370715922, miou=0.7436828874045897, precision=0.7826472167227748, recall=0.9148727400073392\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('logsRA_new_bottleneck_v2/lan4')\n",
    "\n",
    "init_lr = 1e-4\n",
    "batchsize = 8\n",
    "trainsize_init = 384\n",
    "clip = 0.5\n",
    "num_epochs= 30\n",
    "train_save = 'BiRAFPN_4_new_bottleneck_v2'\n",
    "\n",
    "save_path = './snapshots/{}/'.format(train_save)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "else:\n",
    "    print(\"Save path existed\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "log = pd.DataFrame(index=[], columns=[\n",
    "    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n",
    "])\n",
    "train_img_paths = []\n",
    "train_mask_paths = []\n",
    "train_img_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/image/*')\n",
    "train_mask_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/mask/*')\n",
    "train_img_paths.sort()\n",
    "train_mask_paths.sort()\n",
    "\n",
    "train_dataset = Dataset(train_img_paths, train_mask_paths,transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                  compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth').cuda()\n",
    "\n",
    "# ---- flops and params ----\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, init_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                    T_max=len(train_loader)*num_epochs,\n",
    "                                    eta_min=init_lr/1000)\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "ckpt_path = ''\n",
    "if ckpt_path != '':\n",
    "    log = pd.read_csv(ckpt_path.replace('last.pth', 'log.csv'))\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print(\"#\"*20, f\"Start Training\", \"#\"*20)\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n",
    "\n",
    "    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \n",
    "            train_log['loss'].item(), train_log['dice'].item(), train_log['iou'].item(),  \n",
    "    ], index=['epoch', 'lr', 'loss', 'dice', 'iou'])\n",
    "    log = log.append(log_tmp, ignore_index=True)\n",
    "    log.to_csv(f'./snapshots/{train_save}/log.csv', index=False)\n",
    "    writer.add_scalar('training loss',\n",
    "                            train_log['loss'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training dice',\n",
    "                            train_log['dice'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training iou',\n",
    "                            train_log['iou'].item(),\n",
    "                            epoch )\n",
    "    \n",
    "    if epoch >= num_epochs-20:\n",
    "        inference(model,writer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 09:13:18,610 - mmseg - INFO - Use load_from_local loader\n",
      "2022-06-03 09:13:18,682 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.weight, head.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Start Training ####################\n",
      "2022-06-03 09:16:42.538286 Training Epoch [001/030], [loss: 2.4620, dice: 0.7821, iou: 0.6497]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:20:07.197795 Training Epoch [002/030], [loss: 1.5543, dice: 0.8416, iou: 0.7320]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:23:32.140386 Training Epoch [003/030], [loss: 1.4406, dice: 0.8195, iou: 0.7065]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:26:57.092929 Training Epoch [004/030], [loss: 1.3986, dice: 0.8349, iou: 0.7285]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:30:21.743752 Training Epoch [005/030], [loss: 1.1350, dice: 0.8801, iou: 0.7932]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:33:46.512416 Training Epoch [006/030], [loss: 1.0119, dice: 0.9034, iou: 0.8264]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:37:11.401656 Training Epoch [007/030], [loss: 1.0898, dice: 0.8867, iou: 0.8031]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:40:36.266354 Training Epoch [008/030], [loss: 0.9336, dice: 0.9032, iou: 0.8281]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:44:01.089133 Training Epoch [009/030], [loss: 0.9171, dice: 0.9246, iou: 0.8621]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "2022-06-03 09:47:25.896065 Training Epoch [010/030], [loss: 0.8753, dice: 0.9240, iou: 0.8624]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.8789540767807289, miou=0.8182488348768423, precision=0.9433160998187532, recall=0.8560683791373737\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.8924839537131217, miou=0.8403349442672762, precision=0.9119062977056431, recall=0.9203671367641345\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7892608876724996, miou=0.7156843182949199, precision=0.8320690172802058, recall=0.8179992749133814\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8942999480561257, miou=0.8278196934805921, precision=0.8577868985042308, recall=0.9620927008939707\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.764704971426004, miou=0.6793166149361602, precision=0.7407034604134154, recall=0.8340429956108655\n",
      "####################\n",
      "2022-06-03 09:51:54.666128 Training Epoch [011/030], [loss: 0.9283, dice: 0.9044, iou: 0.8330]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9014090679469229, miou=0.8454174967750765, precision=0.9466597160481119, recall=0.8896972774902696\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9074318458008536, miou=0.8535421084400411, precision=0.9018842165969005, recall=0.9427092110704568\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8044694711203071, miou=0.7273801348242942, precision=0.8119527476725356, recall=0.8572872447371138\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8590228087362256, miou=0.7954939217563239, precision=0.823010339720171, recall=0.9465937691294851\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.729334436136706, miou=0.6595728938500037, precision=0.6853777327102824, recall=0.8473514081464859\n",
      "####################\n",
      "2022-06-03 09:56:23.234448 Training Epoch [012/030], [loss: 0.8736, dice: 0.9257, iou: 0.8651]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9013426649956306, miou=0.8452707958221876, precision=0.944815043310377, recall=0.8922581999944537\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9067613540752464, miou=0.8487056914789277, precision=0.9091973917581018, recall=0.9296154406803097\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7597342968041145, miou=0.6824396992179038, precision=0.7700567294683751, recall=0.8092497625525925\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8997990711434841, miou=0.8328184247766516, precision=0.8579022906650974, recall=0.9664536431530554\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8236182241095378, miou=0.739716661546738, precision=0.7740923668438264, recall=0.9421379358811725\n",
      "####################\n",
      "2022-06-03 10:00:52.206600 Training Epoch [013/030], [loss: 0.8836, dice: 0.9248, iou: 0.8618]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9104128340339658, miou=0.8553441169596865, precision=0.928899497930562, recall=0.9119443465287479\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9127793530910705, miou=0.8595053124211676, precision=0.9309772660233905, recall=0.9183931477170905\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7998016306530107, miou=0.718367306165928, precision=0.8278689639083671, recall=0.820995819738628\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.911028794200251, miou=0.8472564328631697, precision=0.8912504881559831, recall=0.9463806062203056\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.733413345665612, miou=0.6678095274755119, precision=0.7002910874047997, recall=0.846948590379452\n",
      "####################\n",
      "2022-06-03 10:05:21.115907 Training Epoch [014/030], [loss: 0.7885, dice: 0.9401, iou: 0.8883]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9115016449639068, miou=0.8542118125541833, precision=0.9463976546893261, recall=0.8985869184984372\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9086885581140096, miou=0.8571086104652067, precision=0.9050499321082872, recall=0.9433689269178455\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8122745820311733, miou=0.733650988205841, precision=0.8144633884734211, recall=0.8753880964548382\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.862476083619082, miou=0.7955080008435677, precision=0.8349768341040218, recall=0.9518704922488784\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7850107718095263, miou=0.7079320972558435, precision=0.7397586286356123, recall=0.9144178920563855\n",
      "####################\n",
      "2022-06-03 10:09:49.676208 Training Epoch [015/030], [loss: 0.8569, dice: 0.9290, iou: 0.8710]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9004414888203679, miou=0.8443789709974128, precision=0.94269712835477, recall=0.894271874551365\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.916382500552154, miou=0.8628541952183045, precision=0.9051397009253533, recall=0.9521529659476633\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.7957810528961546, miou=0.7164079584999303, precision=0.7991150648233998, recall=0.8427011060000139\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.895920766226505, miou=0.8224635420498968, precision=0.8407299624857778, recall=0.9753375905139141\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8103682904418126, miou=0.7264203741193587, precision=0.7513279182297227, recall=0.9293195908430643\n",
      "####################\n",
      "2022-06-03 10:14:18.605026 Training Epoch [016/030], [loss: 0.7949, dice: 0.9319, iou: 0.8764]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9256767807010767, miou=0.8727996521827122, precision=0.9452664968760449, recall=0.920878464465325\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9152139794343633, miou=0.8668518963419728, precision=0.9175386135369008, recall=0.9332468368340446\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7830400078114771, miou=0.7092817691900031, precision=0.7849154510503995, recall=0.8513047172803508\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8549198171197819, miou=0.7873091377514417, precision=0.819334743762231, recall=0.9569365125623067\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.808774785449602, miou=0.7237999374681308, precision=0.7671526573330231, recall=0.908875949174349\n",
      "####################\n",
      "2022-06-03 10:18:47.771493 Training Epoch [017/030], [loss: 0.8019, dice: 0.9227, iou: 0.8667]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9079776922001394, miou=0.8559320011830576, precision=0.9501848245856358, recall=0.8895646607310219\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9231377586691265, miou=0.8730340706928871, precision=0.9300049606412238, recall=0.9369594728679019\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8130668966030107, miou=0.7338195609850215, precision=0.82933908762241, recall=0.8423829209175528\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9073206905307725, miou=0.8433127113944339, precision=0.8738272249184548, recall=0.9611341878702951\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8112638546418565, miou=0.7350055252820897, precision=0.7729657982476927, recall=0.9078024490345485\n",
      "####################\n",
      "2022-06-03 10:23:16.779255 Training Epoch [018/030], [loss: 0.7416, dice: 0.9543, iou: 0.9135]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9080798569103663, miou=0.8546704725523062, precision=0.9412109952560254, recall=0.8966003305450999\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9229926838080147, miou=0.8713720463642829, precision=0.9278013594374828, recall=0.9378775367526834\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8209503075641258, miou=0.7434097679090858, precision=0.8283617735265444, recall=0.863260071948819\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9047871808075295, miou=0.8392078912291188, precision=0.8703367139651927, recall=0.9605639755347025\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.816599051915165, miou=0.7377406102566956, precision=0.7765895779539406, recall=0.9009476339943642\n",
      "####################\n",
      "2022-06-03 10:27:45.236579 Training Epoch [019/030], [loss: 0.7299, dice: 0.9391, iou: 0.8912]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9107523908175107, miou=0.8589021659326939, precision=0.9345673678821267, recall=0.9052359201271557\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9156671585558293, miou=0.8636273851799802, precision=0.9094428848133326, recall=0.9488951078749482\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8223884895055497, miou=0.7480473709283327, precision=0.8275867564054569, recall=0.8584066120620406\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.8962352068577499, miou=0.8309771363935443, precision=0.861305125079476, recall=0.9470206999047961\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8240722258376749, miou=0.7439368705005011, precision=0.776917850909271, recall=0.9311141784206824\n",
      "####################\n",
      "2022-06-03 10:32:13.729150 Training Epoch [020/030], [loss: 0.6862, dice: 0.9433, iou: 0.8971]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9240785639685026, miou=0.8711887109702015, precision=0.9395125225579041, recall=0.9249191734851925\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9273968669020657, miou=0.8806274725786689, precision=0.9394940272943267, recall=0.9346594314798634\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.819926000716814, miou=0.7421985147647457, precision=0.8428312899425643, recall=0.8450691173987813\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9054088753255212, miou=0.8374144448197726, precision=0.8731841238964339, recall=0.9537524693841336\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8302559216631793, miou=0.7528368747169096, precision=0.7872754347525869, recall=0.9305122566467582\n",
      "####################\n",
      "2022-06-03 10:36:42.358394 Training Epoch [021/030], [loss: 0.6815, dice: 0.9546, iou: 0.9139]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9159843558532639, miou=0.8644716110026824, precision=0.9561822038247777, recall=0.9023491839900244\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9204746112533116, miou=0.8700536505515014, precision=0.9314061841546539, recall=0.9309197979786192\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.803505143163178, miou=0.7273925360095201, precision=0.8240340197478655, recall=0.837425155632757\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.909680818714692, miou=0.8432992068845319, precision=0.8822276531559375, recall=0.950128381561622\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8189199488814812, miou=0.7399688003739483, precision=0.7830941863796559, recall=0.9195327470715146\n",
      "####################\n",
      "2022-06-03 10:41:11.245433 Training Epoch [022/030], [loss: 0.7429, dice: 0.9194, iou: 0.8644]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.890689630762167, miou=0.8305888073528993, precision=0.9540968474804897, recall=0.8694107194633964\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.9188308832122313, miou=0.8664419015297443, precision=0.9218559551340705, recall=0.9363618884791473\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7966186448925386, miou=0.7171365905236126, precision=0.8240103429708151, recall=0.8300601802096446\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9008173110695998, miou=0.8345604461920406, precision=0.8708363136620844, recall=0.9427151049354571\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8279400980327775, miou=0.7481035573015008, precision=0.7913366768487006, recall=0.9220582306758865\n",
      "####################\n",
      "2022-06-03 10:45:40.306223 Training Epoch [023/030], [loss: 0.6305, dice: 0.9536, iou: 0.9134]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9180872406536856, miou=0.867845266072731, precision=0.9494707329494644, recall=0.9117265427504823\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9240570036421624, miou=0.8765000620063838, precision=0.9344355612614476, recall=0.9357294571506414\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8151946732443488, miou=0.7408623358147719, precision=0.8336851833544804, recall=0.8446429981421091\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9132791817206493, miou=0.8491362094430431, precision=0.8879534304490132, recall=0.953078347663574\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8206631054519987, miou=0.740579251788033, precision=0.7770203333030408, recall=0.9314504138388628\n",
      "####################\n",
      "2022-06-03 10:50:09.105090 Training Epoch [024/030], [loss: 0.5950, dice: 0.9531, iou: 0.9126]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9255302791062072, miou=0.8747311036542537, precision=0.9404037132585966, recall=0.9277755333583105\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9230026012947516, miou=0.8747259916899336, precision=0.9201304133303111, recall=0.9489139975313438\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8067743866439957, miou=0.7326615120647318, precision=0.8065636293713474, recall=0.8737584639798416\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9019671940533808, miou=0.8356045786299664, precision=0.8636209432348309, recall=0.9644681884622632\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.7921684286023986, miou=0.706892237042082, precision=0.7378117718013536, recall=0.933093112127173\n",
      "####################\n",
      "2022-06-03 10:54:38.063713 Training Epoch [025/030], [loss: 0.6495, dice: 0.9558, iou: 0.9170]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9230969271764331, miou=0.8707842330553874, precision=0.9520396510769215, recall=0.9135136272670806\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9246270495097538, miou=0.8790705294032695, precision=0.9351967745876221, recall=0.9387157936055209\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8153996528979329, miou=0.7401805964549348, precision=0.8301350755543956, recall=0.8558400891602169\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9033349455996832, miou=0.8378943263408599, precision=0.8742608577832378, recall=0.954470131442884\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8207210344964154, miou=0.7398850544286981, precision=0.7805035397070034, recall=0.9232518904904892\n",
      "####################\n",
      "2022-06-03 10:59:06.660905 Training Epoch [026/030], [loss: 0.5877, dice: 0.9602, iou: 0.9241]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9176414462239297, miou=0.8663926198170587, precision=0.9452615765277674, recall=0.9071422472024817\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9412988860064002, miou=0.8954207616336509, precision=0.939634646886069, recall=0.9494613058601137\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7983844589965043, miou=0.7272975993038101, precision=0.8220029898559589, recall=0.828169147194283\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.910186996900113, miou=0.8465113204472554, precision=0.8824709924476625, recall=0.955786598616001\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8307675168445666, miou=0.7565146697414751, precision=0.8155546656375815, recall=0.8951171551096335\n",
      "####################\n",
      "2022-06-03 11:03:35.240599 Training Epoch [027/030], [loss: 0.5393, dice: 0.9630, iou: 0.9292]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9026787621753815, miou=0.8518808356137545, precision=0.9455873210267874, recall=0.8919933127191335\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.930753121609893, miou=0.8841568180382301, precision=0.9403392789505997, recall=0.9366208423192979\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.7931021173461692, miou=0.7249161969416323, precision=0.8145661586107223, recall=0.8165374357712377\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9125078505364831, miou=0.8494028232059877, precision=0.886993007304415, recall=0.954606481473441\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8374150733365416, miou=0.7623982703841581, precision=0.8206062757191637, recall=0.8981900735751347\n",
      "####################\n",
      "2022-06-03 11:08:03.871295 Training Epoch [028/030], [loss: 0.5866, dice: 0.9569, iou: 0.9193]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.926718252712995, miou=0.8763750981367118, precision=0.9465635918325259, recall=0.9241994386417557\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9377674607591785, miou=0.8927826945185838, precision=0.9322928604722832, recall=0.9553582273907986\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.808801861021373, miou=0.7354890112865986, precision=0.8173639150531486, recall=0.8568356011170758\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9043009441912206, miou=0.8378049972684747, precision=0.8716094619658382, recall=0.957911201334746\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8260961468708308, miou=0.7475519391715407, precision=0.7910104904239258, recall=0.917788651522025\n",
      "####################\n",
      "2022-06-03 11:12:32.751066 Training Epoch [029/030], [loss: 0.5948, dice: 0.9640, iou: 0.9310]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: dice=0.926643257826244, miou=0.8764203356342689, precision=0.9480647948163576, recall=0.9226585926585911\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.9395886947143941, miou=0.894074151202363, precision=0.9344919305786795, recall=0.9538248579598031\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8079144732606574, miou=0.7357083357937648, precision=0.8224612087883432, recall=0.8468131622426033\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.9079713449358838, miou=0.8425432966284389, precision=0.8772566440268084, recall=0.9570589941835428\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8320197220013231, miou=0.7566351862512937, precision=0.8066528795415293, recall=0.9113279624918371\n",
      "####################\n",
      "2022-06-03 11:17:01.325326 Training Epoch [030/030], [loss: 0.5950, dice: 0.9630, iou: 0.9294]\n",
      "[Saving Checkpoint:] ./snapshots/BiRAFPN_5_new_bottleneck_v2/last.pth\n",
      "####################\n",
      "../dataset/scenario_4/all_datasets//TestDataset/Kvasir\n",
      "Dataset_name: Kvasir\n",
      "scores: dice=0.9265869181777205, miou=0.8761718851125945, precision=0.9475726546177399, recall=0.9229914593463461\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ClinicDB\n",
      "Dataset_name: CVC-ClinicDB\n",
      "scores: dice=0.940101476335146, miou=0.8944066692377293, precision=0.9352158127278423, recall=0.9534259740812204\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-ColonDB\n",
      "Dataset_name: CVC-ColonDB\n",
      "scores: dice=0.8069502099259226, miou=0.7353614855362046, precision=0.8236289921005616, recall=0.8451920906767982\n",
      "../dataset/scenario_4/all_datasets//TestDataset/CVC-300\n",
      "Dataset_name: CVC-300\n",
      "scores: dice=0.909069943399668, miou=0.8442502004178282, precision=0.878585213385754, recall=0.9576016989261278\n",
      "../dataset/scenario_4/all_datasets//TestDataset/ETIS-LaribPolypDB\n",
      "Dataset_name: ETIS-LaribPolypDB\n",
      "scores: dice=0.8313173069616686, miou=0.7560632144313941, precision=0.8082556814943742, recall=0.9093347866076981\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('logsRA_new_bottleneck_v2/lan5')\n",
    "\n",
    "init_lr = 1e-4\n",
    "batchsize = 8\n",
    "trainsize_init = 384\n",
    "clip = 0.5\n",
    "num_epochs= 30\n",
    "train_save = 'BiRAFPN_5_new_bottleneck_v2'\n",
    "\n",
    "save_path = './snapshots/{}/'.format(train_save)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "else:\n",
    "    print(\"Save path existed\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "log = pd.DataFrame(index=[], columns=[\n",
    "    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n",
    "])\n",
    "train_img_paths = []\n",
    "train_mask_paths = []\n",
    "train_img_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/image/*')\n",
    "train_mask_paths = glob('../dataset/scenario_4/all_datasets/TrainDataset/mask/*')\n",
    "train_img_paths.sort()\n",
    "train_mask_paths.sort()\n",
    "\n",
    "train_dataset = Dataset(train_img_paths, train_mask_paths,transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_step = len(train_loader)\n",
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                  compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth').cuda()\n",
    "\n",
    "# ---- flops and params ----\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, init_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                    T_max=len(train_loader)*num_epochs,\n",
    "                                    eta_min=init_lr/1000)\n",
    "\n",
    "\n",
    "\n",
    "start_epoch = 1\n",
    "\n",
    "ckpt_path = ''\n",
    "if ckpt_path != '':\n",
    "    log = pd.read_csv(ckpt_path.replace('last.pth', 'log.csv'))\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print(\"#\"*20, f\"Start Training\", \"#\"*20)\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n",
    "\n",
    "    log_tmp = pd.Series([epoch, optimizer.param_groups[0][\"lr\"], \n",
    "            train_log['loss'].item(), train_log['dice'].item(), train_log['iou'].item(),  \n",
    "    ], index=['epoch', 'lr', 'loss', 'dice', 'iou'])\n",
    "    log = log.append(log_tmp, ignore_index=True)\n",
    "    log.to_csv(f'./snapshots/{train_save}/log.csv', index=False)\n",
    "    writer.add_scalar('training loss',\n",
    "                            train_log['loss'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training dice',\n",
    "                            train_log['dice'].item(),\n",
    "                            epoch )\n",
    "    writer.add_scalar('training iou',\n",
    "                            train_log['iou'].item(),\n",
    "                            epoch )\n",
    "    \n",
    "    if epoch >= num_epochs-20:\n",
    "        inference(model,writer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 13:45:55,566 - mmseg - INFO - Use load_from_local loader\n",
      "2022-06-03 13:45:55,659 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.weight, head.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93489990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/thuannh/SegFormer_clean/mmseg/models/backbones/mix_transformer.py:98: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/backbones/mix_transformer.py:104: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  kv = self.kv(x_).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/backbones/mix_transformer.py:106: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  kv = self.kv(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/segmentors/utils.py:831: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  left = extra_h // 2\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/segmentors/utils.py:833: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  top = extra_v // 2\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/segmentors/utils.py:870: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  left = extra_h // 2\n",
      "/home/s/thuannh/SegFormer_clean/mmseg/models/segmentors/utils.py:872: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  top = extra_v // 2\n",
      "/home/s/anaconda3/envs/tf2.6/lib/python3.6/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "Unsupported operator aten::div encountered 404 time(s)\n",
      "Unsupported operator aten::mul encountered 271 time(s)\n",
      "Unsupported operator aten::softmax encountered 28 time(s)\n",
      "Unsupported operator aten::add encountered 537 time(s)\n",
      "Unsupported operator aten::gelu encountered 28 time(s)\n",
      "Unsupported operator aten::bernoulli_ encountered 54 time(s)\n",
      "Unsupported operator aten::div_ encountered 54 time(s)\n",
      "Unsupported operator aten::prelu encountered 3 time(s)\n",
      "Unsupported operator aten::rsub encountered 292 time(s)\n",
      "Unsupported operator aten::sub encountered 292 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 30 time(s)\n",
      "Unsupported operator aten::sum encountered 56 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 28 time(s)\n",
      "Unsupported operator prim::PythonOp.SwishImplementation encountered 56 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "RA, RA.ra_conv1, RA.ra_conv1.bn, RA.ra_conv1.conv, RA.ra_conv1.relu, RA.ra_conv2, RA.ra_conv2.bn, RA.ra_conv2.conv, RA.ra_conv2.relu, RA.ra_conv3, RA.ra_conv3.bn, RA.ra_conv3.conv, RA.ra_conv3.relu, agg1, agg1.conv4, agg1.conv4.bn, agg1.conv4.conv, agg1.conv4.relu, agg1.conv5, agg1.conv_concat2, agg1.conv_concat2.bn, agg1.conv_concat2.conv, agg1.conv_concat2.relu, agg1.conv_concat3, agg1.conv_concat3.bn, agg1.conv_concat3.conv, agg1.conv_concat3.relu, agg1.conv_upsample1, agg1.conv_upsample1.bn, agg1.conv_upsample1.conv, agg1.conv_upsample1.relu, agg1.conv_upsample2, agg1.conv_upsample2.bn, agg1.conv_upsample2.conv, agg1.conv_upsample2.relu, agg1.conv_upsample3, agg1.conv_upsample3.bn, agg1.conv_upsample3.conv, agg1.conv_upsample3.relu, agg1.conv_upsample4, agg1.conv_upsample4.bn, agg1.conv_upsample4.conv, agg1.conv_upsample4.relu, agg1.conv_upsample5, agg1.conv_upsample5.bn, agg1.conv_upsample5.conv, agg1.conv_upsample5.relu, agg1.relu, agg1.upsample, bifpn.0.RA_p4_3.latenconv.relu, bifpn.0.RA_p4_3.ra_conv1.relu, bifpn.0.RA_p4_3.ra_conv2.relu, bifpn.0.RA_p4_3.ra_conv3.relu, bifpn.0.RA_p5_4.latenconv.relu, bifpn.0.RA_p5_4.ra_conv1.relu, bifpn.0.RA_p5_4.ra_conv2.relu, bifpn.0.RA_p5_4.ra_conv3.relu, bifpn.0.RA_p6_5.latenconv.relu, bifpn.0.RA_p6_5.ra_conv1.relu, bifpn.0.RA_p6_5.ra_conv2.relu, bifpn.0.RA_p6_5.ra_conv3.relu, bifpn.0.RA_p7_6.latenconv.relu, bifpn.0.RA_p7_6.ra_conv1.relu, bifpn.0.RA_p7_6.ra_conv2.relu, bifpn.0.RA_p7_6.ra_conv3.relu, bifpn.1.RA_p4_3.latenconv.relu, bifpn.1.RA_p4_3.ra_conv1.relu, bifpn.1.RA_p4_3.ra_conv2.relu, bifpn.1.RA_p4_3.ra_conv3.relu, bifpn.1.RA_p5_4.latenconv.relu, bifpn.1.RA_p5_4.ra_conv1.relu, bifpn.1.RA_p5_4.ra_conv2.relu, bifpn.1.RA_p5_4.ra_conv3.relu, bifpn.1.RA_p6_5.latenconv.relu, bifpn.1.RA_p6_5.ra_conv1.relu, bifpn.1.RA_p6_5.ra_conv2.relu, bifpn.1.RA_p6_5.ra_conv3.relu, bifpn.1.RA_p7_6.latenconv.relu, bifpn.1.RA_p7_6.ra_conv1.relu, bifpn.1.RA_p7_6.ra_conv2.relu, bifpn.1.RA_p7_6.ra_conv3.relu, bifpn.2.RA_p4_3.latenconv.relu, bifpn.2.RA_p4_3.ra_conv1.relu, bifpn.2.RA_p4_3.ra_conv2.relu, bifpn.2.RA_p4_3.ra_conv3.relu, bifpn.2.RA_p5_4.latenconv.relu, bifpn.2.RA_p5_4.ra_conv1.relu, bifpn.2.RA_p5_4.ra_conv2.relu, bifpn.2.RA_p5_4.ra_conv3.relu, bifpn.2.RA_p6_5.latenconv.relu, bifpn.2.RA_p6_5.ra_conv1.relu, bifpn.2.RA_p6_5.ra_conv2.relu, bifpn.2.RA_p6_5.ra_conv3.relu, bifpn.2.RA_p7_6.latenconv.relu, bifpn.2.RA_p7_6.ra_conv1.relu, bifpn.2.RA_p7_6.ra_conv2.relu, bifpn.2.RA_p7_6.ra_conv3.relu, bifpn.3.RA_p4_3.latenconv.relu, bifpn.3.RA_p4_3.ra_conv1.relu, bifpn.3.RA_p4_3.ra_conv2.relu, bifpn.3.RA_p4_3.ra_conv3.relu, bifpn.3.RA_p5_4.latenconv.relu, bifpn.3.RA_p5_4.ra_conv1.relu, bifpn.3.RA_p5_4.ra_conv2.relu, bifpn.3.RA_p5_4.ra_conv3.relu, bifpn.3.RA_p6_5.latenconv.relu, bifpn.3.RA_p6_5.ra_conv1.relu, bifpn.3.RA_p6_5.ra_conv2.relu, bifpn.3.RA_p6_5.ra_conv3.relu, bifpn.3.RA_p7_6.latenconv.relu, bifpn.3.RA_p7_6.ra_conv1.relu, bifpn.3.RA_p7_6.ra_conv2.relu, bifpn.3.RA_p7_6.ra_conv3.relu, bifpn.4.RA_p4_3.latenconv.relu, bifpn.4.RA_p4_3.ra_conv1.relu, bifpn.4.RA_p4_3.ra_conv2.relu, bifpn.4.RA_p4_3.ra_conv3.relu, bifpn.4.RA_p5_4.latenconv.relu, bifpn.4.RA_p5_4.ra_conv1.relu, bifpn.4.RA_p5_4.ra_conv2.relu, bifpn.4.RA_p5_4.ra_conv3.relu, bifpn.4.RA_p6_5.latenconv.relu, bifpn.4.RA_p6_5.ra_conv1.relu, bifpn.4.RA_p6_5.ra_conv2.relu, bifpn.4.RA_p6_5.ra_conv3.relu, bifpn.4.RA_p7_6.latenconv.relu, bifpn.4.RA_p7_6.ra_conv1.relu, bifpn.4.RA_p7_6.ra_conv2.relu, bifpn.4.RA_p7_6.ra_conv3.relu, bifpn.5.RA_p4_3.latenconv.relu, bifpn.5.RA_p4_3.ra_conv1.relu, bifpn.5.RA_p4_3.ra_conv2.relu, bifpn.5.RA_p4_3.ra_conv3.relu, bifpn.5.RA_p5_4.latenconv.relu, bifpn.5.RA_p5_4.ra_conv1.relu, bifpn.5.RA_p5_4.ra_conv2.relu, bifpn.5.RA_p5_4.ra_conv3.relu, bifpn.5.RA_p6_5.latenconv.relu, bifpn.5.RA_p6_5.ra_conv1.relu, bifpn.5.RA_p6_5.ra_conv2.relu, bifpn.5.RA_p6_5.ra_conv3.relu, bifpn.5.RA_p7_6.latenconv.relu, bifpn.5.RA_p7_6.ra_conv1.relu, bifpn.5.RA_p7_6.ra_conv2.relu, bifpn.5.RA_p7_6.ra_conv3.relu, bifpn.6.RA_p4_3.latenconv.relu, bifpn.6.RA_p4_3.ra_conv1.relu, bifpn.6.RA_p4_3.ra_conv2.relu, bifpn.6.RA_p4_3.ra_conv3.relu, bifpn.6.RA_p5_4.latenconv.relu, bifpn.6.RA_p5_4.ra_conv1.relu, bifpn.6.RA_p5_4.ra_conv2.relu, bifpn.6.RA_p5_4.ra_conv3.relu, bifpn.6.RA_p6_5.latenconv.relu, bifpn.6.RA_p6_5.ra_conv1.relu, bifpn.6.RA_p6_5.ra_conv2.relu, bifpn.6.RA_p6_5.ra_conv3.relu, bifpn.6.RA_p7_6.latenconv.relu, bifpn.6.RA_p7_6.ra_conv1.relu, bifpn.6.RA_p7_6.ra_conv2.relu, bifpn.6.RA_p7_6.ra_conv3.relu, bifpn.6.conv7_down, bifpn.6.conv7_down.bn, bifpn.6.conv7_down.depthwise_conv, bifpn.6.conv7_down.depthwise_conv.conv, bifpn.6.conv7_down.pointwise_conv, bifpn.6.conv7_down.pointwise_conv.conv, rfb2_1, rfb2_1.branch0, rfb2_1.branch0.0, rfb2_1.branch0.0.bn, rfb2_1.branch0.0.conv, rfb2_1.branch0.0.relu, rfb2_1.branch1, rfb2_1.branch1.0, rfb2_1.branch1.0.bn, rfb2_1.branch1.0.conv, rfb2_1.branch1.0.relu, rfb2_1.branch1.1, rfb2_1.branch1.1.bn, rfb2_1.branch1.1.conv, rfb2_1.branch1.1.relu, rfb2_1.branch1.2, rfb2_1.branch1.2.bn, rfb2_1.branch1.2.conv, rfb2_1.branch1.2.relu, rfb2_1.branch1.3, rfb2_1.branch1.3.bn, rfb2_1.branch1.3.conv, rfb2_1.branch1.3.relu, rfb2_1.branch2, rfb2_1.branch2.0, rfb2_1.branch2.0.bn, rfb2_1.branch2.0.conv, rfb2_1.branch2.0.relu, rfb2_1.branch2.1, rfb2_1.branch2.1.bn, rfb2_1.branch2.1.conv, rfb2_1.branch2.1.relu, rfb2_1.branch2.2, rfb2_1.branch2.2.bn, rfb2_1.branch2.2.conv, rfb2_1.branch2.2.relu, rfb2_1.branch2.3, rfb2_1.branch2.3.bn, rfb2_1.branch2.3.conv, rfb2_1.branch2.3.relu, rfb2_1.branch3, rfb2_1.branch3.0, rfb2_1.branch3.0.bn, rfb2_1.branch3.0.conv, rfb2_1.branch3.0.relu, rfb2_1.branch3.1, rfb2_1.branch3.1.bn, rfb2_1.branch3.1.conv, rfb2_1.branch3.1.relu, rfb2_1.branch3.2, rfb2_1.branch3.2.bn, rfb2_1.branch3.2.conv, rfb2_1.branch3.2.relu, rfb2_1.branch3.3, rfb2_1.branch3.3.bn, rfb2_1.branch3.3.conv, rfb2_1.branch3.3.relu, rfb2_1.conv_cat, rfb2_1.conv_cat.bn, rfb2_1.conv_cat.conv, rfb2_1.conv_cat.relu, rfb2_1.conv_res, rfb2_1.conv_res.bn, rfb2_1.conv_res.conv, rfb2_1.conv_res.relu, rfb2_1.relu, rfb3_1, rfb3_1.branch0, rfb3_1.branch0.0, rfb3_1.branch0.0.bn, rfb3_1.branch0.0.conv, rfb3_1.branch0.0.relu, rfb3_1.branch1, rfb3_1.branch1.0, rfb3_1.branch1.0.bn, rfb3_1.branch1.0.conv, rfb3_1.branch1.0.relu, rfb3_1.branch1.1, rfb3_1.branch1.1.bn, rfb3_1.branch1.1.conv, rfb3_1.branch1.1.relu, rfb3_1.branch1.2, rfb3_1.branch1.2.bn, rfb3_1.branch1.2.conv, rfb3_1.branch1.2.relu, rfb3_1.branch1.3, rfb3_1.branch1.3.bn, rfb3_1.branch1.3.conv, rfb3_1.branch1.3.relu, rfb3_1.branch2, rfb3_1.branch2.0, rfb3_1.branch2.0.bn, rfb3_1.branch2.0.conv, rfb3_1.branch2.0.relu, rfb3_1.branch2.1, rfb3_1.branch2.1.bn, rfb3_1.branch2.1.conv, rfb3_1.branch2.1.relu, rfb3_1.branch2.2, rfb3_1.branch2.2.bn, rfb3_1.branch2.2.conv, rfb3_1.branch2.2.relu, rfb3_1.branch2.3, rfb3_1.branch2.3.bn, rfb3_1.branch2.3.conv, rfb3_1.branch2.3.relu, rfb3_1.branch3, rfb3_1.branch3.0, rfb3_1.branch3.0.bn, rfb3_1.branch3.0.conv, rfb3_1.branch3.0.relu, rfb3_1.branch3.1, rfb3_1.branch3.1.bn, rfb3_1.branch3.1.conv, rfb3_1.branch3.1.relu, rfb3_1.branch3.2, rfb3_1.branch3.2.bn, rfb3_1.branch3.2.conv, rfb3_1.branch3.2.relu, rfb3_1.branch3.3, rfb3_1.branch3.3.bn, rfb3_1.branch3.3.conv, rfb3_1.branch3.3.relu, rfb3_1.conv_cat, rfb3_1.conv_cat.bn, rfb3_1.conv_cat.conv, rfb3_1.conv_cat.relu, rfb3_1.conv_res, rfb3_1.conv_res.bn, rfb3_1.conv_res.conv, rfb3_1.conv_res.relu, rfb3_1.relu, rfb4_1, rfb4_1.branch0, rfb4_1.branch0.0, rfb4_1.branch0.0.bn, rfb4_1.branch0.0.conv, rfb4_1.branch0.0.relu, rfb4_1.branch1, rfb4_1.branch1.0, rfb4_1.branch1.0.bn, rfb4_1.branch1.0.conv, rfb4_1.branch1.0.relu, rfb4_1.branch1.1, rfb4_1.branch1.1.bn, rfb4_1.branch1.1.conv, rfb4_1.branch1.1.relu, rfb4_1.branch1.2, rfb4_1.branch1.2.bn, rfb4_1.branch1.2.conv, rfb4_1.branch1.2.relu, rfb4_1.branch1.3, rfb4_1.branch1.3.bn, rfb4_1.branch1.3.conv, rfb4_1.branch1.3.relu, rfb4_1.branch2, rfb4_1.branch2.0, rfb4_1.branch2.0.bn, rfb4_1.branch2.0.conv, rfb4_1.branch2.0.relu, rfb4_1.branch2.1, rfb4_1.branch2.1.bn, rfb4_1.branch2.1.conv, rfb4_1.branch2.1.relu, rfb4_1.branch2.2, rfb4_1.branch2.2.bn, rfb4_1.branch2.2.conv, rfb4_1.branch2.2.relu, rfb4_1.branch2.3, rfb4_1.branch2.3.bn, rfb4_1.branch2.3.conv, rfb4_1.branch2.3.relu, rfb4_1.branch3, rfb4_1.branch3.0, rfb4_1.branch3.0.bn, rfb4_1.branch3.0.conv, rfb4_1.branch3.0.relu, rfb4_1.branch3.1, rfb4_1.branch3.1.bn, rfb4_1.branch3.1.conv, rfb4_1.branch3.1.relu, rfb4_1.branch3.2, rfb4_1.branch3.2.bn, rfb4_1.branch3.2.conv, rfb4_1.branch3.2.relu, rfb4_1.branch3.3, rfb4_1.branch3.3.bn, rfb4_1.branch3.3.conv, rfb4_1.branch3.3.relu, rfb4_1.conv_cat, rfb4_1.conv_cat.bn, rfb4_1.conv_cat.conv, rfb4_1.conv_cat.relu, rfb4_1.conv_res, rfb4_1.conv_res.bn, rfb4_1.conv_res.conv, rfb4_1.conv_res.relu, rfb4_1.relu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50090527836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net2( backbone=dict(\n",
    "                  type='mit_b3',\n",
    "                  style='pytorch'), \n",
    "              decode_head=dict(\n",
    "                  type='UPerHead',\n",
    "                  in_channels=[64, 128, 320, 448],\n",
    "                  in_index=[0, 1, 2, 3],\n",
    "                  channels=128,\n",
    "                  dropout_ratio=0.1,\n",
    "                  num_classes=1,\n",
    "                  norm_cfg=dict(type='BN', requires_grad=True),\n",
    "                   compound_coef=4,\n",
    "                  align_corners=False,\n",
    "                  decoder_params=dict(embed_dim=768),\n",
    "                  loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n",
    "              neck=None,\n",
    "             compound_coef=4,\n",
    "              auxiliary_head=None,\n",
    "              train_cfg=dict(),\n",
    "              test_cfg=dict(mode='whole'),\n",
    "              pretrained='pretrained/mit_b3.pth')\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "from pthflops import count_ops\n",
    "print(count_parameters(model))\n",
    "x = torch.rand(1,3,384,384)\n",
    "#count_ops(model, x,mode='jit')\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "flops = FlopCountAnalysis(model, x)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  3 13:45:54 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 50%   32C    P8    43W / 350W |     31MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       916      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1201      G   /usr/bin/gnome-shell                8MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,random, glob\n",
    "import matplotlib.pyplot as plt\n",
    "files = glob.glob(\"../dataset/ISIC/traindataset/images/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in files:\n",
    "    name = path.split(\"/\")[-1]\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image,(384,384))\n",
    "    cv2.imwrite(\"../dataset/ISIC/384/traindataset/images/\"+name,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1815 1815\n"
     ]
    }
   ],
   "source": [
    "print(len(glob.glob(\"../dataset/ISIC/traindataset/images/*\")),len(glob.glob(\"../dataset/ISIC/384/traindataset/images/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PolypFormer B4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
